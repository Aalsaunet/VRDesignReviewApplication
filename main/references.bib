@ARTICLE {VRS2016,
	author  = {Rose Leadem},
	title   = {Applications Of Virtual Reality},
	journal = {Virtual Reality Society},
	year    = {2016}
}

@ARTICLE {TO:DNVGL,
	author = {Karl Jeffery},
	title   = {Dnv Gl to Unveil Rules This Year},
	journal = {Tanker Operator},
	year    = {2015}
}

@ARTICLE {MTN:DNVGL,
	author = {Claudio Paschoa},
	title   = {JIP Collapse Assessment of Offshore Pipelines with D/t < 15},
	journal = {Marine Technology News},
	year    = {2013}
}

@ARTICLE{Mitra2007, 
	author={S. Mitra and T. Acharya}, 
	journal={IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)}, 
	title={Gesture Recognition: A Survey}, 
	year={2007}, 
	volume={37}, 
	number={3}, 
	pages={311-324},  
	doi={10.1109/TSMCC.2007.893280}, 
	ISSN={1094-6977}, 
	month={May}
}

@Article{Rautaray2015,
	author="Rautaray, Siddharth S.
	and Agrawal, Anupam",
	title="Vision based hand gesture recognition for human computer interaction: a survey",
	journal="Artificial Intelligence Review",
	year="2015",
	volume="43",
	number="1",
	pages="1--54",
	issn="1573-7462",
	doi="10.1007/s10462-012-9356-9",
	url="http://dx.doi.org/10.1007/s10462-012-9356-9"
}

@Article{Lee2007,
	author={Kue-Bum Lee, Jung-Hyun Kim and Kwang-Seok Hong},
	journal={Fifth International Conference on Software Engineering Research, Management and Applications}, 
	title={An Implementation of Multi-Modal Game Interface Based on PDAs}, 
	year={2007}
}

@Article{Myo2015,
	author = {Curtis Silver},
	journal = {Forbes}, 
	title = {Gift This, Not That: Myo Armband vs This Toaster},
	year = {2015}
}

@Article{LeapMotion2016,
	author = {Alex Colgan},
	journal = {developer.leapmotion.com}, 
	title = {Controller - Leap Motion JavaScript SDK v2.3 documentation},
	year = {2016}
}

@article{Nishikawa2003,
	author    = {Atsushi Nishikawa and
	Toshinori Hosoi and
	Kengo Koara and
	Daiji Negoro and
	Ayae Hikita and
	Shuichi Asano and
	Haruhiko Kakutani and
	Fumio Miyazaki and
	Mitsugu Sekimoto and
	Masayoshi Yasui and
	Yasuhiro Miyake and
	Shuji Takiguchi and
	Morito Monden},
	title     = {FAce MOUSe: {A} novel human-machine interface for controlling the
	position of a laparoscope},
	journal   = {{IEEE} Trans. Robotics and Automation},
	volume    = {19},
	number    = {5},
	pages     = {825--841},
	year      = {2003},
	url       = {http://dx.doi.org/10.1109/TRA.2003.817093},
	doi       = {10.1109/TRA.2003.817093},
	timestamp = {Wed, 09 Mar 2016 15:54:16 +0100},
	biburl    = {http://dblp.uni-trier.de/rec/bib/journals/trob/NishikawaHKNHAKMSYMTM03},
	bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{Schultz2003,
	ISSN = {0899823X, 15596834},
	URL = {http://www.jstor.org/stable/10.1086/502200},
	abstract = {ABSTRACT We tested 100 keyboards in 29 clinical areas for bacterial contamination. Ninety five were positive for microorganisms. Streptococcus, Clostridium perfringens, Enterococcus (including one vancomycin‐resistant Enterococcus), Staphylococcus aureus, fungi, and gram‐negative organisms were isolated. Computer equipment must be kept clean so it does not become another vehicle for transmission of pathogens to patients.},
	author = {Maureen Schultz, Janet Gill, Sabiha Zubairi, Ruth Huber, Fred Gordin},
	journal = {Infection Control and Hospital Epidemiology},
	number = {4},
	pages = {302-303},
	publisher = {[Cambridge University Press, Society for Healthcare Epidemiology of America]},
	title = {Bacterial Contamination of Computer Keyboards in a Teaching Hospital},
	volume = {24},
	year = {2003}
}

@article{Ko2012,
	abstract = {Over the past few years, gesture recognition has made its debut in entertainment and gaming markets. Now, gesture recognition is becoming a commonplace technology, enabling humans and machines to interface more easily in the home, the automobile and at work. Imagine a person sitting on a couch, controlling the lights and TV with a wave of his hand. This and other capabilities are being realized as gesture recognition technologies enable natural interactions with the electronics that surround us. Gesture recognition has long been researched with 2D vision, but with the advent of 3D sensor technology, its applications are now more diverse, spanning a variety of markets.},
	author = {Ko, Dong-ik and Agarwal, Gaurav},
	file = {:D$\backslash$:/Dropbox/Privat/Master/Reference documents/Gesture recognition - Enabling natural interactions with electronics.pdf:pdf},
	keywords = {3D,graphics,hardware,interactions,porcessor,software,vision},
	pages = {13},
	title = {{Gesture recognition : enabling natural interactions with electronics}},
	year = {2012}
}

@article{Guna2014,
	abstract = {We present the results of an evaluation of the performance of the Leap Motion Controller with the aid of a professional, high-precision, fast motion tracking system. A set of static and dynamic measurements was performed with different numbers of tracking objects and configurations. For the static measurements, a plastic arm model simulating a human arm was used. A set of 37 reference locations was selected to cover the controller's sensory space. For the dynamic measurements, a special V-shaped tool, consisting of two tracking objects maintaining a constant distance between them, was created to simulate two human fingers. In the static scenario, the standard deviation was less than 0.5 mm. The linear correlation revealed a significant increase in the standard deviation when moving away from the controller. The results of the dynamic scenario revealed the inconsistent performance of the controller, with a significant drop in accuracy for samples taken more than 250 mm above the controller's surface. The Leap Motion Controller undoubtedly represents a revolutionary input device for gesture-based human-computer interaction; however, due to its rather limited sensory space and inconsistent sampling frequency, in its current configuration it cannot currently be used as a professional tracking system.},
	author = {Guna, Jo{\v{z}}e and Jakus, Grega and Poga{\v{c}}nik, Matev{\v{z}} and Toma{\v{z}}i{\v{c}}, Sa{\v{s}}o and Sodnik, Jaka},
	doi = {10.3390/s140203702},
	file = {:D$\backslash$:/Dropbox/Privat/Master/Reference documents/sensors-14-03702.pdf:pdf},
	isbn = {1424-8220},
	issn = {14248220},
	journal = {Sensors (Switzerland)},
	keywords = {Leap motion controller,Motion capture system,Precision measurement,Spatial distortion measurement},
	number = {2},
	pages = {3702--3720},
	pmid = {24566635},
	title = {{An analysis of the precision and reliability of the leap motion sensor and its suitability for static and dynamic tracking}},
	volume = {14},
	year = {2014}
}

@article{Weichert2013,
	abstract = {The Leap Motion Controller is a new device for hand gesture controlled user interfaces with declared sub-millimeter accuracy. However, up to this point its capabilities in real environments have not been analyzed. Therefore, this paper presents a first study of a Leap Motion Controller. The main focus of attention is on the evaluation of the accuracy and repeatability. For an appropriate evaluation, a novel experimental setup was developed making use of an industrial robot with a reference pen allowing a position accuracy of 0.2 mm. Thereby, a deviation between a desired 3D position and the average measured positions below 0.2 mm has been obtained for static setups and of 1.2 mm for dynamic setups. Using the conclusion of this analysis can improve the development of applications for the Leap Motion controller in the field of Human-Computer Interaction.},
	author = {Weichert, Frank and Bachmann, Daniel and Rudak, Bartholom{\"{a}}us and Fisseler, Denis},
	doi = {10.3390/s130506380},
	file = {:C$\backslash$:/Users/Andreas/Downloads/sensors-13-06380.pdf:pdf},
	isbn = {1424-8220 (Electronic)$\backslash$r1424-8220 (Linking)},
	issn = {14248220},
	journal = {Sensors (Switzerland)},
	keywords = {Accuracy,Leap Motion Controller,Measurement precision,Robustness},
	number = {5},
	pages = {6380--6393},
	pmid = {23673678},
	title = {{Analysis of the accuracy and robustness of the Leap Motion Controller}},
	volume = {13},
	year = {2013}
}

@article{Wei2016,
	author = {Lu, Wei and Tong, Zheng and Chu, Jinghui},
	doi = {10.1109/LSP.2016.2590470},
	file = {:C$\backslash$:/Users/Andreas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lu, Tong, Chu - 2016 - Dynamic Hand Gesture Recognition With Leap Motion Controller.pdf:pdf},
	isbn = {2147483648},
	issn = {1070-9908},
	journal = {IEEE Signal Processing Letters},
	month = {sep},
	number = {9},
	pages = {1188--1192},
	title = {{Dynamic Hand Gesture Recognition With Leap Motion Controller}},
	url = {http://ieeexplore.ieee.org/document/7509645/},
	volume = {23},
	year = {2016}
}

@article{Wang2010, 
	author={X. Wang and X. Li}, 
	booktitle={The 2nd International Conference on Information Science and Engineering}, 
	title={The study of MovingTarget tracking based on Kalman-CamShift in the video}, 
	year={2010}, 
	pages={1-4}, 
	keywords={Covariance matrix;Histograms;Image color analysis;Kalman filters;Prediction algorithms;Probability distribution;Target tracking;CamShift;Kalman filter;tacking target}, 
	doi={10.1109/ICISE.2010.5690826}, 
	ISSN={2160-1283}, 
	month={Dec}
}

@article{Cote2006, 
	author={M. Cote and P. Payeur and G. Comeau}, 
	booktitle={Proceedings of the 2006 IEEE International Workshop on Imagining Systems and Techniques (IST 2006)}, 
	title={Comparative Study of Adaptive Segmentation Techniques for Gesture Analysis in Unconstrained Environments}, 
	year={2006}, 
	pages={28-33}, 
	keywords={Computer vision;Image analysis;Image segmentation;Impedance;Information analysis;Information technology;Measurement;Music;Performance analysis;Performance evaluation}, 
	doi={10.1109/IST.2006.1650770}, 
	ISSN={1558-2809}, 
	month={April}
}

@article{Benton1995,
	author = {Benton, Stephen A},
	file = {:D$\backslash$:/Dropbox/Privat/Master/Reference documents/Visual Recognition of American Sign Language Using HMM.pdf:pdf},
	title = {{Visual Recognition of American Sign Language Using Hidden Markov Models Accepted by}},
	year = {1995}
}

